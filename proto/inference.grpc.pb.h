// Generated by the gRPC C++ plugin.
// If you make any local change, they will be lost.
// source: inference.proto
#ifndef GRPC_inference_2eproto__INCLUDED
#define GRPC_inference_2eproto__INCLUDED

#include "inference.pb.h"

#include <functional>
#include <grpcpp/impl/codegen/async_generic_service.h>
#include <grpcpp/impl/codegen/async_stream.h>
#include <grpcpp/impl/codegen/async_unary_call.h>
#include <grpcpp/impl/codegen/client_callback.h>
#include <grpcpp/impl/codegen/client_context.h>
#include <grpcpp/impl/codegen/completion_queue.h>
#include <grpcpp/impl/codegen/message_allocator.h>
#include <grpcpp/impl/codegen/method_handler.h>
#include <grpcpp/impl/codegen/proto_utils.h>
#include <grpcpp/impl/codegen/rpc_method.h>
#include <grpcpp/impl/codegen/server_callback.h>
#include <grpcpp/impl/codegen/server_callback_handlers.h>
#include <grpcpp/impl/codegen/server_context.h>
#include <grpcpp/impl/codegen/service_type.h>
#include <grpcpp/impl/codegen/status.h>
#include <grpcpp/impl/codegen/stub_options.h>
#include <grpcpp/impl/codegen/sync_stream.h>

namespace inference {

// The inference service definition.
class InferenceService final {
 public:
  static constexpr char const* service_full_name() {
    return "inference.InferenceService";
  }
  class StubInterface {
   public:
    virtual ~StubInterface() {}
    // Sends a batch and receives a classification.
    std::unique_ptr< ::grpc::ClientReaderWriterInterface< ::inference::Request, ::inference::Response>> PredictBatch(::grpc::ClientContext* context) {
      return std::unique_ptr< ::grpc::ClientReaderWriterInterface< ::inference::Request, ::inference::Response>>(PredictBatchRaw(context));
    }
    std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>> AsyncPredictBatch(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>>(AsyncPredictBatchRaw(context, cq, tag));
    }
    std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>> PrepareAsyncPredictBatch(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>>(PrepareAsyncPredictBatchRaw(context, cq));
    }
    // Sends a batch and receives a classification while receive and send on server side happens async.
    std::unique_ptr< ::grpc::ClientReaderWriterInterface< ::inference::Request, ::inference::Response>> PredictBatchAsync(::grpc::ClientContext* context) {
      return std::unique_ptr< ::grpc::ClientReaderWriterInterface< ::inference::Request, ::inference::Response>>(PredictBatchAsyncRaw(context));
    }
    std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>> AsyncPredictBatchAsync(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>>(AsyncPredictBatchAsyncRaw(context, cq, tag));
    }
    std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>> PrepareAsyncPredictBatchAsync(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>>(PrepareAsyncPredictBatchAsyncRaw(context, cq));
    }
    // Shuts down the server.
    virtual ::grpc::Status ShutdownServer(::grpc::ClientContext* context, const ::inference::Empty& request, ::inference::Empty* response) = 0;
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::inference::Empty>> AsyncShutdownServer(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::inference::Empty>>(AsyncShutdownServerRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::inference::Empty>> PrepareAsyncShutdownServer(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReaderInterface< ::inference::Empty>>(PrepareAsyncShutdownServerRaw(context, request, cq));
    }
    class async_interface {
     public:
      virtual ~async_interface() {}
      // Sends a batch and receives a classification.
      virtual void PredictBatch(::grpc::ClientContext* context, ::grpc::ClientBidiReactor< ::inference::Request,::inference::Response>* reactor) = 0;
      // Sends a batch and receives a classification while receive and send on server side happens async.
      virtual void PredictBatchAsync(::grpc::ClientContext* context, ::grpc::ClientBidiReactor< ::inference::Request,::inference::Response>* reactor) = 0;
      // Shuts down the server.
      virtual void ShutdownServer(::grpc::ClientContext* context, const ::inference::Empty* request, ::inference::Empty* response, std::function<void(::grpc::Status)>) = 0;
      virtual void ShutdownServer(::grpc::ClientContext* context, const ::inference::Empty* request, ::inference::Empty* response, ::grpc::ClientUnaryReactor* reactor) = 0;
    };
    typedef class async_interface experimental_async_interface;
    virtual class async_interface* async() { return nullptr; }
    class async_interface* experimental_async() { return async(); }
   private:
    virtual ::grpc::ClientReaderWriterInterface< ::inference::Request, ::inference::Response>* PredictBatchRaw(::grpc::ClientContext* context) = 0;
    virtual ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>* AsyncPredictBatchRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) = 0;
    virtual ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>* PrepareAsyncPredictBatchRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientReaderWriterInterface< ::inference::Request, ::inference::Response>* PredictBatchAsyncRaw(::grpc::ClientContext* context) = 0;
    virtual ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>* AsyncPredictBatchAsyncRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) = 0;
    virtual ::grpc::ClientAsyncReaderWriterInterface< ::inference::Request, ::inference::Response>* PrepareAsyncPredictBatchAsyncRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::inference::Empty>* AsyncShutdownServerRaw(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) = 0;
    virtual ::grpc::ClientAsyncResponseReaderInterface< ::inference::Empty>* PrepareAsyncShutdownServerRaw(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) = 0;
  };
  class Stub final : public StubInterface {
   public:
    Stub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());
    std::unique_ptr< ::grpc::ClientReaderWriter< ::inference::Request, ::inference::Response>> PredictBatch(::grpc::ClientContext* context) {
      return std::unique_ptr< ::grpc::ClientReaderWriter< ::inference::Request, ::inference::Response>>(PredictBatchRaw(context));
    }
    std::unique_ptr<  ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>> AsyncPredictBatch(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>>(AsyncPredictBatchRaw(context, cq, tag));
    }
    std::unique_ptr<  ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>> PrepareAsyncPredictBatch(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>>(PrepareAsyncPredictBatchRaw(context, cq));
    }
    std::unique_ptr< ::grpc::ClientReaderWriter< ::inference::Request, ::inference::Response>> PredictBatchAsync(::grpc::ClientContext* context) {
      return std::unique_ptr< ::grpc::ClientReaderWriter< ::inference::Request, ::inference::Response>>(PredictBatchAsyncRaw(context));
    }
    std::unique_ptr<  ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>> AsyncPredictBatchAsync(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>>(AsyncPredictBatchAsyncRaw(context, cq, tag));
    }
    std::unique_ptr<  ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>> PrepareAsyncPredictBatchAsync(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>>(PrepareAsyncPredictBatchAsyncRaw(context, cq));
    }
    ::grpc::Status ShutdownServer(::grpc::ClientContext* context, const ::inference::Empty& request, ::inference::Empty* response) override;
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::inference::Empty>> AsyncShutdownServer(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::inference::Empty>>(AsyncShutdownServerRaw(context, request, cq));
    }
    std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::inference::Empty>> PrepareAsyncShutdownServer(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) {
      return std::unique_ptr< ::grpc::ClientAsyncResponseReader< ::inference::Empty>>(PrepareAsyncShutdownServerRaw(context, request, cq));
    }
    class async final :
      public StubInterface::async_interface {
     public:
      void PredictBatch(::grpc::ClientContext* context, ::grpc::ClientBidiReactor< ::inference::Request,::inference::Response>* reactor) override;
      void PredictBatchAsync(::grpc::ClientContext* context, ::grpc::ClientBidiReactor< ::inference::Request,::inference::Response>* reactor) override;
      void ShutdownServer(::grpc::ClientContext* context, const ::inference::Empty* request, ::inference::Empty* response, std::function<void(::grpc::Status)>) override;
      void ShutdownServer(::grpc::ClientContext* context, const ::inference::Empty* request, ::inference::Empty* response, ::grpc::ClientUnaryReactor* reactor) override;
     private:
      friend class Stub;
      explicit async(Stub* stub): stub_(stub) { }
      Stub* stub() { return stub_; }
      Stub* stub_;
    };
    class async* async() override { return &async_stub_; }

   private:
    std::shared_ptr< ::grpc::ChannelInterface> channel_;
    class async async_stub_{this};
    ::grpc::ClientReaderWriter< ::inference::Request, ::inference::Response>* PredictBatchRaw(::grpc::ClientContext* context) override;
    ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>* AsyncPredictBatchRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) override;
    ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>* PrepareAsyncPredictBatchRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientReaderWriter< ::inference::Request, ::inference::Response>* PredictBatchAsyncRaw(::grpc::ClientContext* context) override;
    ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>* AsyncPredictBatchAsyncRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq, void* tag) override;
    ::grpc::ClientAsyncReaderWriter< ::inference::Request, ::inference::Response>* PrepareAsyncPredictBatchAsyncRaw(::grpc::ClientContext* context, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::inference::Empty>* AsyncShutdownServerRaw(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) override;
    ::grpc::ClientAsyncResponseReader< ::inference::Empty>* PrepareAsyncShutdownServerRaw(::grpc::ClientContext* context, const ::inference::Empty& request, ::grpc::CompletionQueue* cq) override;
    const ::grpc::internal::RpcMethod rpcmethod_PredictBatch_;
    const ::grpc::internal::RpcMethod rpcmethod_PredictBatchAsync_;
    const ::grpc::internal::RpcMethod rpcmethod_ShutdownServer_;
  };
  static std::unique_ptr<Stub> NewStub(const std::shared_ptr< ::grpc::ChannelInterface>& channel, const ::grpc::StubOptions& options = ::grpc::StubOptions());

  class Service : public ::grpc::Service {
   public:
    Service();
    virtual ~Service();
    // Sends a batch and receives a classification.
    virtual ::grpc::Status PredictBatch(::grpc::ServerContext* context, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* stream);
    // Sends a batch and receives a classification while receive and send on server side happens async.
    virtual ::grpc::Status PredictBatchAsync(::grpc::ServerContext* context, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* stream);
    // Shuts down the server.
    virtual ::grpc::Status ShutdownServer(::grpc::ServerContext* context, const ::inference::Empty* request, ::inference::Empty* response);
  };
  template <class BaseClass>
  class WithAsyncMethod_PredictBatch : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithAsyncMethod_PredictBatch() {
      ::grpc::Service::MarkMethodAsync(0);
    }
    ~WithAsyncMethod_PredictBatch() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatch(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestPredictBatch(::grpc::ServerContext* context, ::grpc::ServerAsyncReaderWriter< ::inference::Response, ::inference::Request>* stream, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncBidiStreaming(0, context, stream, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_PredictBatchAsync : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithAsyncMethod_PredictBatchAsync() {
      ::grpc::Service::MarkMethodAsync(1);
    }
    ~WithAsyncMethod_PredictBatchAsync() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatchAsync(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestPredictBatchAsync(::grpc::ServerContext* context, ::grpc::ServerAsyncReaderWriter< ::inference::Response, ::inference::Request>* stream, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncBidiStreaming(1, context, stream, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithAsyncMethod_ShutdownServer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithAsyncMethod_ShutdownServer() {
      ::grpc::Service::MarkMethodAsync(2);
    }
    ~WithAsyncMethod_ShutdownServer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownServer(::grpc::ServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestShutdownServer(::grpc::ServerContext* context, ::inference::Empty* request, ::grpc::ServerAsyncResponseWriter< ::inference::Empty>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(2, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  typedef WithAsyncMethod_PredictBatch<WithAsyncMethod_PredictBatchAsync<WithAsyncMethod_ShutdownServer<Service > > > AsyncService;
  template <class BaseClass>
  class WithCallbackMethod_PredictBatch : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithCallbackMethod_PredictBatch() {
      ::grpc::Service::MarkMethodCallback(0,
          new ::grpc::internal::CallbackBidiHandler< ::inference::Request, ::inference::Response>(
            [this](
                   ::grpc::CallbackServerContext* context) { return this->PredictBatch(context); }));
    }
    ~WithCallbackMethod_PredictBatch() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatch(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    virtual ::grpc::ServerBidiReactor< ::inference::Request, ::inference::Response>* PredictBatch(
      ::grpc::CallbackServerContext* /*context*/)
      { return nullptr; }
  };
  template <class BaseClass>
  class WithCallbackMethod_PredictBatchAsync : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithCallbackMethod_PredictBatchAsync() {
      ::grpc::Service::MarkMethodCallback(1,
          new ::grpc::internal::CallbackBidiHandler< ::inference::Request, ::inference::Response>(
            [this](
                   ::grpc::CallbackServerContext* context) { return this->PredictBatchAsync(context); }));
    }
    ~WithCallbackMethod_PredictBatchAsync() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatchAsync(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    virtual ::grpc::ServerBidiReactor< ::inference::Request, ::inference::Response>* PredictBatchAsync(
      ::grpc::CallbackServerContext* /*context*/)
      { return nullptr; }
  };
  template <class BaseClass>
  class WithCallbackMethod_ShutdownServer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithCallbackMethod_ShutdownServer() {
      ::grpc::Service::MarkMethodCallback(2,
          new ::grpc::internal::CallbackUnaryHandler< ::inference::Empty, ::inference::Empty>(
            [this](
                   ::grpc::CallbackServerContext* context, const ::inference::Empty* request, ::inference::Empty* response) { return this->ShutdownServer(context, request, response); }));}
    void SetMessageAllocatorFor_ShutdownServer(
        ::grpc::MessageAllocator< ::inference::Empty, ::inference::Empty>* allocator) {
      ::grpc::internal::MethodHandler* const handler = ::grpc::Service::GetHandler(2);
      static_cast<::grpc::internal::CallbackUnaryHandler< ::inference::Empty, ::inference::Empty>*>(handler)
              ->SetMessageAllocator(allocator);
    }
    ~WithCallbackMethod_ShutdownServer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownServer(::grpc::ServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    virtual ::grpc::ServerUnaryReactor* ShutdownServer(
      ::grpc::CallbackServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/)  { return nullptr; }
  };
  typedef WithCallbackMethod_PredictBatch<WithCallbackMethod_PredictBatchAsync<WithCallbackMethod_ShutdownServer<Service > > > CallbackService;
  typedef CallbackService ExperimentalCallbackService;
  template <class BaseClass>
  class WithGenericMethod_PredictBatch : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithGenericMethod_PredictBatch() {
      ::grpc::Service::MarkMethodGeneric(0);
    }
    ~WithGenericMethod_PredictBatch() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatch(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_PredictBatchAsync : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithGenericMethod_PredictBatchAsync() {
      ::grpc::Service::MarkMethodGeneric(1);
    }
    ~WithGenericMethod_PredictBatchAsync() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatchAsync(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithGenericMethod_ShutdownServer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithGenericMethod_ShutdownServer() {
      ::grpc::Service::MarkMethodGeneric(2);
    }
    ~WithGenericMethod_ShutdownServer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownServer(::grpc::ServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
  };
  template <class BaseClass>
  class WithRawMethod_PredictBatch : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawMethod_PredictBatch() {
      ::grpc::Service::MarkMethodRaw(0);
    }
    ~WithRawMethod_PredictBatch() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatch(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestPredictBatch(::grpc::ServerContext* context, ::grpc::ServerAsyncReaderWriter< ::grpc::ByteBuffer, ::grpc::ByteBuffer>* stream, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncBidiStreaming(0, context, stream, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_PredictBatchAsync : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawMethod_PredictBatchAsync() {
      ::grpc::Service::MarkMethodRaw(1);
    }
    ~WithRawMethod_PredictBatchAsync() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatchAsync(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestPredictBatchAsync(::grpc::ServerContext* context, ::grpc::ServerAsyncReaderWriter< ::grpc::ByteBuffer, ::grpc::ByteBuffer>* stream, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncBidiStreaming(1, context, stream, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawMethod_ShutdownServer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawMethod_ShutdownServer() {
      ::grpc::Service::MarkMethodRaw(2);
    }
    ~WithRawMethod_ShutdownServer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownServer(::grpc::ServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    void RequestShutdownServer(::grpc::ServerContext* context, ::grpc::ByteBuffer* request, ::grpc::ServerAsyncResponseWriter< ::grpc::ByteBuffer>* response, ::grpc::CompletionQueue* new_call_cq, ::grpc::ServerCompletionQueue* notification_cq, void *tag) {
      ::grpc::Service::RequestAsyncUnary(2, context, request, response, new_call_cq, notification_cq, tag);
    }
  };
  template <class BaseClass>
  class WithRawCallbackMethod_PredictBatch : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawCallbackMethod_PredictBatch() {
      ::grpc::Service::MarkMethodRawCallback(0,
          new ::grpc::internal::CallbackBidiHandler< ::grpc::ByteBuffer, ::grpc::ByteBuffer>(
            [this](
                   ::grpc::CallbackServerContext* context) { return this->PredictBatch(context); }));
    }
    ~WithRawCallbackMethod_PredictBatch() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatch(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    virtual ::grpc::ServerBidiReactor< ::grpc::ByteBuffer, ::grpc::ByteBuffer>* PredictBatch(
      ::grpc::CallbackServerContext* /*context*/)
      { return nullptr; }
  };
  template <class BaseClass>
  class WithRawCallbackMethod_PredictBatchAsync : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawCallbackMethod_PredictBatchAsync() {
      ::grpc::Service::MarkMethodRawCallback(1,
          new ::grpc::internal::CallbackBidiHandler< ::grpc::ByteBuffer, ::grpc::ByteBuffer>(
            [this](
                   ::grpc::CallbackServerContext* context) { return this->PredictBatchAsync(context); }));
    }
    ~WithRawCallbackMethod_PredictBatchAsync() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status PredictBatchAsync(::grpc::ServerContext* /*context*/, ::grpc::ServerReaderWriter< ::inference::Response, ::inference::Request>* /*stream*/)  override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    virtual ::grpc::ServerBidiReactor< ::grpc::ByteBuffer, ::grpc::ByteBuffer>* PredictBatchAsync(
      ::grpc::CallbackServerContext* /*context*/)
      { return nullptr; }
  };
  template <class BaseClass>
  class WithRawCallbackMethod_ShutdownServer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithRawCallbackMethod_ShutdownServer() {
      ::grpc::Service::MarkMethodRawCallback(2,
          new ::grpc::internal::CallbackUnaryHandler< ::grpc::ByteBuffer, ::grpc::ByteBuffer>(
            [this](
                   ::grpc::CallbackServerContext* context, const ::grpc::ByteBuffer* request, ::grpc::ByteBuffer* response) { return this->ShutdownServer(context, request, response); }));
    }
    ~WithRawCallbackMethod_ShutdownServer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable synchronous version of this method
    ::grpc::Status ShutdownServer(::grpc::ServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    virtual ::grpc::ServerUnaryReactor* ShutdownServer(
      ::grpc::CallbackServerContext* /*context*/, const ::grpc::ByteBuffer* /*request*/, ::grpc::ByteBuffer* /*response*/)  { return nullptr; }
  };
  template <class BaseClass>
  class WithStreamedUnaryMethod_ShutdownServer : public BaseClass {
   private:
    void BaseClassMustBeDerivedFromService(const Service* /*service*/) {}
   public:
    WithStreamedUnaryMethod_ShutdownServer() {
      ::grpc::Service::MarkMethodStreamed(2,
        new ::grpc::internal::StreamedUnaryHandler<
          ::inference::Empty, ::inference::Empty>(
            [this](::grpc::ServerContext* context,
                   ::grpc::ServerUnaryStreamer<
                     ::inference::Empty, ::inference::Empty>* streamer) {
                       return this->StreamedShutdownServer(context,
                         streamer);
                  }));
    }
    ~WithStreamedUnaryMethod_ShutdownServer() override {
      BaseClassMustBeDerivedFromService(this);
    }
    // disable regular version of this method
    ::grpc::Status ShutdownServer(::grpc::ServerContext* /*context*/, const ::inference::Empty* /*request*/, ::inference::Empty* /*response*/) override {
      abort();
      return ::grpc::Status(::grpc::StatusCode::UNIMPLEMENTED, "");
    }
    // replace default version of method with streamed unary
    virtual ::grpc::Status StreamedShutdownServer(::grpc::ServerContext* context, ::grpc::ServerUnaryStreamer< ::inference::Empty,::inference::Empty>* server_unary_streamer) = 0;
  };
  typedef WithStreamedUnaryMethod_ShutdownServer<Service > StreamedUnaryService;
  typedef Service SplitStreamedService;
  typedef WithStreamedUnaryMethod_ShutdownServer<Service > StreamedService;
};

}  // namespace inference


#endif  // GRPC_inference_2eproto__INCLUDED
